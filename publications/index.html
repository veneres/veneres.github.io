<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Publications | Alberto  Veneri</title>
    <meta name="author" content="Alberto  Veneri" />
    <meta name="description" content="Publications in reversed chronological order" />
    <meta name="keywords" content="explainable artificial intelligence, information retrieval" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>🔭</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://veneres.github.io/publications/">
    
    <!-- Dark Mode -->
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Alberto&nbsp;</span>Veneri</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              
              <!-- Blog 
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">blog</a>
              </li>
              -->

              <!-- Other pages -->
              <li class="nav-item active">
                <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a>
              </li>
            </ul>
          </div>
        </div>
      </nav>

    </header>


    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Publications</h1>
            <p class="post-description">Publications in reversed chronological order</p>
          </header>

          <article>
            <!-- _pages/publications.md -->
<div class="publications">
  <h2 class="year">2023</h2>
  <ol class="bibliography"><li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"></div>

        <!-- Entry bib key -->
        <div id="lucchese_gam_2023" class="col-sm-8">
        <!-- Title -->
        <div class="title">GAM Forest Explanation</div>
        <!-- Author -->
        <div class="author">
        

        Claudio Lucchese,&nbsp;Salvatore Orlando,&nbsp;Raffaele Perego, and
          <span class="more-authors" title="click to view 1 more author" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '1 more author' ? 'Alberto Veneri' : '1 more author';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">1 more author</span></div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://openproceedings.org/2023/conf/edbt/paper-207.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
            <a href="https://github.com/veneres/gef" class="btn btn-sm z-depth-0" role="button">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.48786/EDBT.2023.14"></span>
              <span class="__dimensions_badge_embed__" data-doi="10.48786/EDBT.2023.14" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Most accurate machine learning models unfortunately produce black-box predictions, for which it is impossible to grasp the internal logic that leads to a speci c decision. Unfolding the logic of such black-box models is of increasing importance, especially when they are used in sensitive decision-making processes. In this work we focus on forests of decision trees, which may include hundreds to thousands of decision trees to produce accurate predictions. Such complexity raises the need of developing explanations for the predictions generated by large forests. We propose a post hoc explanation method of large forests, named GAM-based Explanation of Forests (GEF), which builds a Generalized Additive Model (GAM) able to explain, both locally and globally, the impact on the predictions of a limited set of features and feature interactions. We evaluate GEF over both synthetic and real-world datasets and show that GEF can create a GAM model with high delity by analyzing the given forest only and without using any further information, not even the initial training dataset.</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography"><li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"></div>

        <!-- Entry bib key -->
        <div id="lucchese_ilmart_2022" class="col-sm-8">
        <!-- Title -->
        <div class="title">ILMART: Interpretable Ranking with Constrained LambdaMART</div>
        <!-- Author -->
        <div class="author">
        

        Claudio Lucchese,&nbsp;Franco Maria Nardini,&nbsp;Salvatore Orlando, and
          <span class="more-authors" title="click to view 2 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '2 more authors' ? 'Raffaele Perego, Alberto Veneri' : '2 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">2 more authors</span></div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval</em>, Jul 2022
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dl.acm.org/doi/abs/10.1145/3477495.3531840" class="btn btn-sm z-depth-0" role="button">PDF</a>
            <a href="https://github.com/veneres/ilmart" class="btn btn-sm z-depth-0" role="button">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1145/3477495.3531840"></span>
              <span class="__dimensions_badge_embed__" data-doi="10.1145/3477495.3531840" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Interpretable Learning to Rank (LtR) is an emerging field within the research area of explainable AI, aiming at developing intelligible and accurate predictive models. While most of the previous research efforts focus on creating post-hoc explanations, in this paper we investigate how to train effective and intrinsically-interpretable ranking models. Developing these models is particularly challenging and it also requires finding a trade-off between ranking quality and model complexity. State-of-the-art rankers, made of either large ensembles of trees or several neural layers, exploit in fact an unlimited number of feature interactions making them black boxes. Previous approaches on intrinsically-interpretable ranking models address this issue by avoiding interactions between features thus paying a significant performance drop with respect to full-complexity models. Conversely, ILMART, our novel and interpretable LtR solution based on LambdaMART, is able to train effective and intelligible models by exploiting a limited and controlled number of pairwise feature interactions. Exhaustive and reproducible experiments conducted on three publicly-available LtR datasets show that ILMART outperforms the current state-of-the-art solution for interpretable ranking of a large margin with a gain of nDCG of up to 8%.</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"></div>

        <!-- Entry bib key -->
        <div id="burch_exploring_2020" class="col-sm-8">
        <!-- Title -->
        <div class="title">Exploring eye movement data with image-based clustering</div>
        <!-- Author -->
        <div class="author">
        

        Michael Burch,&nbsp;Alberto Veneri,&nbsp;and&nbsp;Bangjie Sun</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Journal of Visualization</em>, Aug 2020
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://link.springer.com/article/10.1007/s12650-020-00656-9" class="btn btn-sm z-depth-0" role="button">PDF</a>
            <a href="https://github.com/veneres/EyeCloud" class="btn btn-sm z-depth-0" role="button">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1007/s12650-020-00656-9"></span>
              <span class="__dimensions_badge_embed__" data-doi="10.1007/s12650-020-00656-9" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In this article, we describe a new feature for exploring eye movement data based on image-based clustering. To reach this goal, visual attention is taken into account to compute a list of thumbnail images from the presented stimulus. These thumbnails carry information about visual scanning strategies, but showing them just in a space-ﬁlling and unordered fashion does not support the detection of patterns over space, time, or study participants. In this article, we present an enhancement of the EyeCloud approach that is based on standard word cloud layouts adapted to image thumbnails by exploiting image information to cluster and group the thumbnails that are visually attended. To also indicate the temporal sequence of the thumbnails, we add color-coded links and further visual features to dig deeper in the visual attention data. The usefulness of the technique is illustrated by applying it to eye movement data from a formerly conducted eye tracking experiment investigating route ﬁnding tasks in public transport maps. Finally, we discuss limitations and scalability issues of the approach.</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography"><li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"></div>

        <!-- Entry bib key -->
        <div id="burch_eyeclouds_2019" class="col-sm-8">
        <!-- Title -->
        <div class="title">EyeClouds: A Visualization and Analysis Tool for Exploring Eye Movement Data</div>
        <!-- Author -->
        <div class="author">
        

        Michael Burch,&nbsp;Alberto Veneri,&nbsp;and&nbsp;Bangjie Sun</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Proceedings of the 12th International Symposium on Visual Information Communication and Interaction</em>, Sep 2019
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dl.acm.org/doi/10.1145/3356422.3356423" class="btn btn-sm z-depth-0" role="button">PDF</a>
            <a href="https://github.com/veneres/EyeCloud" class="btn btn-sm z-depth-0" role="button">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1145/3356422.3356423"></span>
              <span class="__dimensions_badge_embed__" data-doi="10.1145/3356422.3356423" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In this paper, we discuss and evaluate the advantages and disadvantages of several techniques to visualize and analyze eye movement data tracked and recorded from public transport map viewers in a formerly conducted eye tracking experiment. Such techniques include heat maps and gaze stripes. To overcome the disadvantages and improve the effectiveness of those techniques, we present a viable solution that makes use of existing techniques such as heat maps and gaze stripes, as well as attention clouds which are inspired by the general concept of word clouds. We also develop a web application with interactive attention clouds, named the EyeCloud, to put theory into practice. The main objective of this paper is to help public transport map designers and producers gain feedback and insights on how the current design of the map can be further improved, by leveraging on the visualization tool. In addition, this visualization tool, the EyeCloud, can be easily extended to many other purposes with various types of data. It could be possibly applied to entertainment industries, for instance, to track the attention of the film audiences in order to improve the advertisements.</p>
          </div>
        </div>
      </div>
</li></ol>


</div>

          </article>

        </div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        &copy; Copyright 2023 Alberto  Veneri. Powered by <a href="https://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.Last updated: April 30, 2023.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
    <!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    

    
    

  </body>
</html>
